## MCMCglmm

```{r}
#| echo: false
gryphon <- read.csv("data/gryphon.csv")
gryphon$animal <- as.factor(gryphon$animal)
gryphon$mother <- as.factor(gryphon$mother)
gryphon$byear <- as.factor(gryphon$byear)
gryphon$sex <- as.factor(gryphon$sex)
gryphon$bwt <- as.numeric(gryphon$bwt)
gryphon$tarsus <- as.numeric(gryphon$tarsus)
gryphonped <- read.csv("data/gryphonped.csv")
gryphonped$id <- as.factor(gryphonped$id)
gryphonped$father <- as.factor(gryphonped$father)
gryphonped$mother <- as.factor(gryphonped$mother)
```

### Running the model
First load `MCMCglmm` library:

```{r}
library(MCMCglmm)
```

The first model we will fit is a simple animal model with no fixed effects, and only an ‘animal’ random effect relating individuals to their additive genetic values through the pedigree. 

First, we are going to define the priors. In a way we might want to avoid using priors, because we would like all of the information in our analysis to come from our data. But bayesian framework use the prior information and the dataset to create posterior distribution of the output model.
By default, MCMCglmm uses improper priors, but it can cause inferential and numerical problems. Thus, we will specify priors for the animal effect and the residual variance using the following code:

```{r}
prior1.1 <- list(
  G = list(G1 = list(V = 1, nu = 0.002)),
  R = list(V = 1, nu = 0.002)
)
```

A prior allowed the model to fit different variance structures. With the unique random effect "animal", we partitioned the phenotypic variance into two distinct variances matrices `G` (additive genetic) and `R` (residual).
This prior specification is the simplistic one and often used because it is believed to be relatively uninformative and is equivalent to an inverse-gamma prior with shape and scale equal to 0.001. In many cases it is relatively uninformative but when the posterior distribution for the variances has close to zero it can behave poorly. Parameter expanded priors (See Chapter 8 of the MCMCglmm CourseNotes, available from CRAN) are gaining in popularity due to their better behaviour but for the purposes of this tutorial we will stick with the inverse-gamma prior. 
We have told MCMCglmm to pay little heed to our prior expectation (V) by specifying a small degree of belief parameter (nu) of 0.002. Since this is a univariate analysis, the priors are matrix of order 1 and thus nu>0 is the smallest degree of belief that provides what is known as a ‘proper’ prior, avoiding numerical problems. In fact, there is a lot of information in the data regarding the marginal distributions of the parameters, and MCMCglmm will run most of the models that we suggest in these tutorials without priors. However, this is poor practice, but we will therefore use this simple prior throughout these tutorials. 
We can now fit an animal model. The model decomposes the phenotypic variation in birth weight `bwt` into genetic and residual effects :
The lower case “animal” can be a **special** word for MCMCglmm. If a `pedigree` argument is provided in the model, then `MCMCglmm` will recognize the term `animal` as the term to use to estimate additive genetic variance. When the argument `pedigree` is not provided then the word `animal` is not different than any other variable. However, instead of providing a pedigree argument within MCMCglmm function, it is much more flexible to use the `ginv` argument to specify the random effect that must be linked to the pedigree (with the inverse relatedness matrix). We thus first estimate the inverse relatedness matrix using `inverseA()` then fit the animal model.

```{r}
#| cache: true
Ainv <- inverseA(gryphonped)$Ainv
model1.1 <- MCMCglmm(bwt ~ 1,
  random = ~animal, ginv = list(animal = Ainv),
  data = gryphon, prior = prior1.1
)
```

After typing this code, MCMCglmm will run, taking about 20 seconds on a modern desktop computer. The progress of the run will be printed to the screen. Note: a warning message will be printed at the end of the run, but its is natural. 
In order for the MCMC algorithm to work, MCMCglmm must keep track of effects associated with unmeasured individuals appearing in the pedigree. This will not affect the answers, but when many unmeasured individuals exist, it can hinder the ability of the algorithm to explore the parameter space (more on this, and a solution, later). Let’s have a look at the MCMCglmm outputs. First, we will evaluate how confident we can be that MCMCglmm found good answers. By entering:

```{r}
#| fig-cap: The posterior distribution of the fixed effect (the intercept, or mean) in
#|   model 1.1
plot(model1.1$Sol)
```

in the console, we get the figure above. The plot on the left shows a time series of values of 1000 samples of the posterior distribution of the model intercept (mean birth weight). The plot on the right shows the same data as a distribution. Complicated statistical methods for estimating population means are of course of little interest; rather, we are examining these outputs to check that MCMCglmm algorithms worked well for our data and for this model. The important point here is that a consistent amount of variation around a largely unchanging mean value of the intercept was obtained (which give this fluctuating trace concentrated around the mean), and the posterior distribution of the intercept appears to be valid. More rigorous means of evaluation the independence of the samples in the posterior distribution (evaluating autocorrelation) are discussed in the MCMCglmm CourseNotes, available from CRAN. Note that your output for `model 1.1` may not be identical to your due to Monte Carlo (random number) error. So, every time, you run the model, you will get similar but slightly different results. 

The posterior distributions of the variance components are generally of more interest to animal model users. We can view plots of the posterior distribution for the variance components for model 1.1 by:

```{r}
#| fig-cap: The posterior distributions of the variance components of model 1.1, based
#|   on an analysis with the default values for nitt, burnin, and thin in MCMCglmm
plot(model1.1$VCV)
```

which generates the figure above. Here, we see the distributions of the additive genetic (animal) and residual (units) effects. These samples contain some autocorrelation, i.e., trends are apparent in the left-hand plot. We can deal with this easily.


### Change in iteration and sampling

We will simply re-run the model for a longer number of iterations and sample the chain less frequently. So far, we have been running MCMCglmm with its default values. These defaults are a total run length of 13000 iterations, the first 3000 of which are discarded as a ‘burn-in’ period to make sure that the converges to the part of the parameter space where the maximum likelihood exists. The remaining 10000 iterations are sampled (estimates retained) every 10 iterations (the thinning interval). Because the values in the left-hand plots in the figure above appear to have different values at the beginning of the run, we might suspect that a longer burn-in period might be required. We can reduce the autocorrelation by lengthening the rest of the run and sampling the chain less frequently. The following code runs the same model 1.1 but is likely to produce better samples of the posterior distributions. This model should take about two minutes to analyze.

```{r}
#| cache: true
model1.1 <- MCMCglmm(bwt ~ 1,
  random = ~animal, ginv = list(animal = Ainv),
  data = gryphon, nitt = 65000, thin = 50, burnin = 15000,
  prior = prior1.1, verbose = FALSE
)
```

Notes that we have now included the argument verbose=FALSE in the MCMCglmm call. We will continue this throughout the tutorial so that more complete screen outputs can be included in this document without using too much space. 
Note that the autocorrelation is much reduced. A more compact way to evaluate the validity of the posterior distributions is to calculate autocorrelation among samples, as follows:

```{r}
autocorr.diag(model1.1$VCV)
```

We will consider these levels of autocorrelation acceptable, at least for the purposes of this tutorial. Ideally, all samples of the posterior distribution should be independent, and the autocorrelation for all lag values greater than zero should be near zero. However, in practice this will not strictly be achievable for all analytic scenarios. Certainly, the levels of autocorrelation observed here should not be tolerated in any formal analysis. 
Note that the validity of posterior distributions of any analysis should always be checked; however, for brevity we will not continue to be so consistently diligent throughout the rest of these tutorials. We can now proceed with confidence to recover some more information from these samples. We can obtain estimates of the additive genetic and residual variance by calculating the modes of the posterior distributions:

```{r}
posterior.mode(model1.1$VCV)
```

We can obtain the Bayesian equivalent of confidence intervals by calculating the the values of the estimates that bound 95% (or any other proportion) of the posterior distributions:

```{r}
HPDinterval(model1.1$VCV)
```

### Change priors’ parameters
We specified weak priors in these analyses. Now we will check whether or not proper priors would have influenced the results that we obtained. The simplest way to do this is to re-run the model with different priors. 
In the previous model we specified a prior where the size of genetic and residual variances was similar. Here we construct priors with a larger degree of belief parameter (`nu`), and we will specify that a large proportion (95 %) of the phenotypic variation is under genetic control (`V`). Thus, the residual variance contains 05 % of the phenotypic variance.

```{r}
#| cache: true
p.var <- var(gryphon$bwt, na.rm = TRUE)
prior1.1.2 <- list(
  G = list(G1 = list(V = matrix(p.var * 0.95), nu = 1)),
  R = list(V = matrix(p.var * 0.05), nu = 1)
)

model1.1.2 <- MCMCglmm(bwt ~ 1,
  random = ~animal, ginv = list(animal = Ainv),
  data = gryphon, prior = prior1.1.2, nitt = 65000, thin = 50,
  burnin = 15000, verbose = FALSE
)
posterior.mode(model1.1$VCV)
posterior.mode(model1.1.2$VCV)
```

and we can therefore conclude that the difference in the priors has little effect on the outcome of the analysis. This is typical for an analysis where lots of data are available relative to the complexity of the model but is often not the case. In all cases, it is important to check the effect of priors on conclusions drawn from a model. In addition, you can also specify the prior with previous knowledge or expectation for the variance.


### Estimating heritability

A useful property of Bayesian posterior distributions is that we can apply almost any transformation to these distributions, and they will remain valid and keep the uncertainty. This applies to the calculation of heritability. We can obtain an estimate of the heritability by applying the basic formula $h^2$ =$V_A /V_P$ to each sample of the posterior distribution:

```{r}
posterior.heritability1.1 <- model1.1$VCV[, "animal"] /
  (model1.1$VCV[, "animal"] + model1.1$VCV[, "units"])

posterior.mode(posterior.heritability1.1)
HPDinterval(posterior.heritability1.1, 0.95)
```

Generate a plot of the posterior distribution of this heritability estimate:

```{r}
#| fig-cap: The posterior distributions the heritability from model 1.1
plot(posterior.heritability1.1)
```

### Adding fixed effects

To add effects to a univariate model, we simply modify the fixed effect part of the model specification:

```{r}
#| cache: true
model1.2 <- MCMCglmm(bwt ~ sex,
  random = ~animal, ginv = list(animal = Ainv),
  data = gryphon, prior = prior1.1,
  nitt = 65000, thin = 50, burnin = 15000, verbose = FALSE
)
summary(model1.2)
```

We can assess the significance of `sex` as a fixed effect by examining its posterior distribution. Important notes here, it is important to know how the model names their fixed effect level to call them properly. 

```{r}
posterior.mode(model1.2$Sol[, "sex2"])
HPDinterval(model1.2$Sol[, "sex2"], 0.95)
```

The posterior distribution of the `sex2` term does not overlap zero. Thus, we can infer that sex has an effect on birth weight (presence of a sexual dimorphism) in this model and is a useful addition to the model. It is also worth noting that the variance components have changed slightly:

```{r}
posterior.mode(model1.2$VCV)
```

In fact, sex effects were contributing to the residual variance of the model our estimate of $V_R$ (denoted ’units’ in the output) is now slightly lower than before. This has an important consequence for estimating heritability since if we calculate $V_P$ as $V_A +V_R$ then as we include fixed effects, we will soak up more residual variance driving $V_P$ . Assuming that $V_A$ is more or less unaffected by the fixed effects fitted then as $V_P$ goes down we expect our estimate of $h^2$ will go up.

```{r}
posterior.heritability1.2 <- model1.2$VCV[, "animal"] /
  (model1.2$VCV[, "animal"] + model1.2$VCV[, "units"])
posterior.mode(posterior.heritability1.2)
HPDinterval(posterior.heritability1.2, 0.95)
```

Here $h^2$ has increased slightly from `r round(posterior.mode(posterior.heritability1.2))` to `r round(posterior.mode(posterior.heritability1.1))`(again, your values may differ slightly due to Monte Carlo error). Which is the better estimate? 
It depends on what your question is. The first is an estimate of the proportion of variance in birth weight explained by additive effects, the latter is an estimate of the proportion of variance in birth weight after conditioning on sex that is explained by additive effects.
An important piece of advice, each researcher should be consistent in how they name their estimates and always correctly describe which estimates they are using conditional or not (to avoid any confusion).

### Adding random effects

This is done by simply modifying the model statement in the same way but requires to modify the prior to include the new random effect. For instance, we can add a random effect of birth year:

```{r}
#| cache: true
prior1.3 <- list(
  G = list(G1 = list(V = 1, nu = 0.002), G2 = list(V = 1, nu = 0.002)),
  R = list(V = 1, nu = 0.002)
)

model1.3 <- MCMCglmm(bwt ~ sex,
  random = ~ animal + byear, ginv = list(animal = Ainv),
  data = gryphon,
  nitt = 65000, thin = 50, burnin = 15000,
  prior = prior1.3, verbose = FALSE
)

posterior.mode(model1.3$VCV)
```

Here the variance in birth weight explained by birth year is `r round(posterior.mode(model1.3$VCV)[2],2)`. Thus, we would conclude that year-to-year variation (e.g., in weather, resource abundance) contributes to the $V_P$. Note that although $V_A$ has changed somewhat, most of what is now partitioned as a `birth year` effect was previously partitioned as $V_R$ . Thus, what we have really done here is to partition environmental effects into those arising from year-to-year differences versus everything else, and we do not really expect much change in $h^2$ (since now $h^2 = V_A /(V_A + V_{BY} + V_R )$). However, we get a somewhat different result if we also add a random effect of `mother` to test for maternal effects:

```{r}
#| cache: true
prior1.4 <- list(
  G = list(
    G1 = list(V = 1, nu = 0.002),
    G2 = list(V = 1, nu = 0.002),
    G3 = list(V = 1, nu = 0.002)
  ),
  R = list(V = 1, nu = 0.002)
)

model1.4 <- MCMCglmm(bwt ~ sex,
  random = ~ animal + byear + mother,
  ginv = list(animal = Ainv), data = gryphon,
  nitt = 65000, thin = 50, burnin = 15000,
  prior = prior1.4, verbose = FALSE
)

posterior.mode(model1.4$VCV)
```

Here partitioning of significant maternal variance has resulted in a further decrease in $V_R$ but also a decrease in $V_A$. The latter is because maternal effects of the sort we simulated (fixed differences between mothers) will have the consequence of increasing similarity among maternal siblings. Consequently, they can look very much like an additive genetic effect and if present, but unmodelled, represent a type of ‘common environment effect’ that can - and will- cause upward bias in $V_A$ and so $h^2$.  The “common environment” can be conceived as the inextricable sum of the maternal additive genetic effect (such as maternal loci) and the maternal environment or permanent environment (such as litter or nest environment created or modified by the mother).
Let’s compare the estimates of heritability from each of models 1.2, 1.3 and 1.4:

```{r}
posterior.heritability1.3 <- model1.3$VCV[, "animal"] /
  (model1.3$VCV[, "animal"] + model1.3$VCV[, "byear"] + model1.3$VCV[, "units"])
posterior.heritability1.4 <- model1.4$VCV[, "animal"] /
  (
    model1.4$VCV[, "animal"] + model1.4$VCV[, "byear"] +
      model1.4$VCV[, "mother"] + model1.4$VCV[, "units"]
  )
posterior.mode(posterior.heritability1.2)
posterior.mode(posterior.heritability1.3)
posterior.mode(posterior.heritability1.4)
```


### Testing significance of variance components

While testing the significance of fixed effects by evaluating whether or not their posterior distributions overlap zero was simple and valid, this approach does not work for variance components. 
Variance components are bounded to be positive (given a proper prior), and thus even when a random effect is not meaningful, its posterior distribution will never overlap zero (but can be dangerously close to it). Model comparisons can be performed using the deviance information criterion (`DIC`), although it should be noted that the properties of DIC are not well understood and that the `DIC` may be focused on the wrong level for most people’s intended level of inference - particularly with non-Gaussian responses. The implementation of `DIC` in MCMCglmm is further described in the reference manual. `DIC` values are calculated by MCMCglmm by default. Briefly, `DIC` like other information criteria balance model fit and model complexity simultaneously, and small values of DIC are preferred. We can compare `models 1.4` and `1.3`, i.e., models with and without the mother term:

```{r}
model1.3$DIC
model1.4$DIC
```

`model 1.4` has a much lower DIC value. Since the maternal effect term is the only difference between the models, we can consider the inclusion of this term statistically justifiable. We should note however that DIC has a large sampling variance and should probably only be calculated based on much longer MCMC runs.

Note that methodology to compare Bayesian models is a intense area of research, so keep in mind this part can change in the future. 

### Further partitioning variance

A population can be further fragmented into different groups or categories (such as females and males, juveniles and adults or treated and untreated). Some scientific questions require further and deeper analysis of the variance of each group. 
To avoid multiple models (one for each group), we can directly partition the variance between groups in a unique model. In addition, by doing so, we can also test if the variance is different between groups.
As example, we can partition the additive genetic variance and residual variance by sex. It is possible to further partition the other variances but that level of complexity for an animal model requires large sample size.   

```{r}
#| cache: true
prior1.4.SEX <- list(
  G = list(
    G1 = list(V = diag(2), nu = 1.002),
    G2 = list(V = diag(2), nu = 1.002),
    G3 = list(V = diag(2), nu = 1.002)
  ),
  R = list(V = diag(2), nu = 1.002)
)

model1.4.SEX <- MCMCglmm(bwt ~ sex,
  random = ~ idh(sex):animal + idh(sex):byear + idh(sex):mother,
  rcov = ~ idh(sex):units,
  ginv = list(animal = Ainv), data = gryphon,
  # nitt = 65000, thin = 50, burnin = 15000, #previous parameter
  nitt = 130000, thin = 100, burnin = 30000,
  prior = prior1.4.SEX, verbose = FALSE
)

posterior.mode(model1.4.SEX$VCV)

posterior.heritability1.4.FEM <- model1.4.SEX$VCV[, "sex1.animal"] /
  (model1.4.SEX$VCV[, "sex1.animal"] + model1.4.SEX$VCV[, "sex1.byear"] +
    model1.4.SEX$VCV[, "sex1.mother"] + model1.4.SEX$VCV[, "sex1.units"])
posterior.heritability1.4.MAL <- model1.4.SEX$VCV[, "sex2.animal"] /
  (model1.4.SEX$VCV[, "sex2.animal"] + model1.4.SEX$VCV[, "sex2.byear"] +
    model1.4.SEX$VCV[, "sex2.mother"] + model1.4.SEX$VCV[, "sex2.units"])

posterior.mode(posterior.heritability1.4.FEM)
HPDinterval(posterior.heritability1.4.FEM, 0.95)
posterior.mode(posterior.heritability1.4.MAL)
HPDinterval(posterior.heritability1.4.MAL, 0.95)
```

Here, we can estimate the heritability for each sex. Both doesn't overlap with zero, so we can conclude both sexes have significant heritability. However, due to their overlaps CIs, we can not conclude the heritability is significantly different between sexes. 
An important quote to remember is "A difference in significance is not a significant difference" 

```{r}
#| fig-cap: Female and male heritability of birth weight
h2.sex <- rbind(
  cbind(
    posterior.mode(posterior.heritability1.4.FEM),
    HPDinterval(posterior.heritability1.4.FEM, 0.95)
  ),
  cbind(
    posterior.mode(posterior.heritability1.4.MAL),
    HPDinterval(posterior.heritability1.4.MAL, 0.95)
  )
)

plot(c(0.95, 1.05) ~ h2.sex[, 1],
  xlim = c(0, 0.8), ylim = c(0.5, 1.5),
  xlab = "", ylab = "", col = c("red", "blue"),
  pch = c(16, 17), cex = 2, yaxt = "n"
)
arrows(
  y0 = 0.95, x0 = h2.sex[1, 2], y1 = 0.95, x1 = h2.sex[1, 3],
  code = 3, angle = 90, length = 0, col = c("red"), lwd = 2
)
arrows(
  y0 = 1.05, x0 = h2.sex[2, 2], y1 = 1.05, x1 = h2.sex[2, 3],
  code = 3, angle = 90, length = 0, col = c("blue"), lwd = 2
)
mtext("Narrow-sense heritability (±CI)",
  side = 1, las = 1, adj = 0.4, line = 3, cex = 1.6
)
axis(2, at = 1, labels = c("birth weight"), las = 3, cex.axis = 1.6)
```

### Modification of model parameter

Unfortunately (to our knowledge), it is not possible to alter the variance matrices and refit them within the model. It is possible to alter the prior to support some change in the variance matrix but it is impossible to compare model properly. 

### Covariance between two random effects

Some research questions require to estimate the covariance between two random effects within a univariate model. To do so, we can use the argument `str`. A similar argument or linking.function `mm` can be used but it will force the variance of `animal` and `mother` to be equal and the covariance to 1, while `str` allows covariances to exist between multiple random terms. Note that  the levels of all multiple random terms have to be the same.
As an example, we fit a model which estimate the covariance between the additive genetic variance and the mother variance. Both variances require to operate on the same level, thus `animal` and `mother` require to be associated to the pedigree information. The ginverse list name has to correspond to the first term in the argument or linking.function. 

```{r}
#| eval: false
#| cache: true
levels(gryphon$mother) <- levels(gryphon$animal)
#
prior1.5 <- list(
  G = list(
    G1 = list(V = diag(2), nu = 1.002),
    G2 = list(V = diag(1), nu = 0.002)
  ),
  R = list(V = 1, nu = 0.002)
)
model1.5 <- MCMCglmm(bwt ~ sex,
  random = ~ str(animal + mother) + byear,
  ginv = list(animal = Ainv, mother = Ainv),
  rcov = ~ idh(1):units,
  data = gryphon,
  nitt = 130000, thin = 100, burnin = 30000,
  prior = prior1.5, verbose = FALSE
)
posterior.mode(model1.5$VCV)
summary(model1.5$VCV)
```

### Reaction norm and plasticity

Since we know how to partition the variance across different levels or group within population (sex as example). It is also possible to partition across environment (character stat approach) which allow to estimate the variance and covariance across levels of environment. There is an alternative way to visualize and estimate the change in variance between environment using a reaction norm known as plasticity. Instead to estimate variance at each level, we can modelized the slope of variance change across environments as a continuous variable.  
Note: Reaction norms are easier to estimate than character state approach, due to the fact that the reaction norm involved a univariate model with a slope whereas the character states approach involves a hybrid of multivariate model.  
For this example, we decide to use sex as an environment, thus estimating the reaction norm across sex, but usually researchers focus on environment. 

```{r}
prior1.6 <- list(
  G = list(
    G1 = list(V = diag(2), nu = 1.002),
    G2 = list(V = 1, nu = 0.002),
    G3 = list(V = 1, nu = 0.002)
  ),
  R = list(V = diag(1), nu = 0.002)
)
model1.6 <- MCMCglmm(bwt ~ sex,
  random = ~ us(1 + sex):animal + byear + mother,
  rcov = ~ idh(1):units,
  ginv = list(animal = Ainv),
  data = gryphon, nitt = 65000, thin = 50, burnin = 15000,
  prior = prior1.6, verbose = FALSE
)
posterior.mode(model1.6$VCV)
```

To implement a reaction norm between groups, we first need to change the prior to produce a 2x2 matrix for the targeted random effect and use the function `us(1+sex):` to produce the unstructured matrix between intercept, slope, and interaction between both.  `(Intercept):(Intercept).animal ‘refers to the genetic variation in intercept, ` sex2:sex2.animal`refers to the genetic slope (reaction norm at the genetic level) and the rest is the covariance between the intercept and the slope.

Interestingly, both models ( reaction norm and character states) are intertown in their equation, and a possible back transformation can be executed. `Part in progress, we try the hard work`

```{r}
RN_Matrix <- matrix(NA, ncol = 2, nrow = 2)
RN_Matrix[1:4] <- as.numeric(posterior.mode(model1.6$VCV)[1:4])
Q <- matrix(c(1, 1, -1, 1), nrow = 2, ncol = 2)
tQQinv <- solve(crossprod(Q))
CS_Matrix <- tQQinv %*% t(Q) %*% RN_Matrix %*% Q %*% t(tQQinv)
```


